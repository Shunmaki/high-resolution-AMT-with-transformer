{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2daaea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank # use 'magphase' to extract phase informatinon with magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f1e9a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "565f5dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize and conv block\n",
    "def init_layer(layer):\n",
    "    \"\"\"Initialize a Linear or Convolutional layer. \"\"\"\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    " \n",
    "    if hasattr(layer, 'bias'):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "            \n",
    "    \n",
    "def init_bn(bn):\n",
    "    \"\"\"Initialize a Batchnorm layer. \"\"\"\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.)\n",
    "\n",
    "\n",
    "def init_gru(rnn):\n",
    "    \"\"\"Initialize a GRU layer. \"\"\"\n",
    "    \n",
    "    def _concat_init(tensor, init_funcs):\n",
    "        (length, fan_out) = tensor.shape\n",
    "        fan_in = length // len(init_funcs)\n",
    "    \n",
    "        for (i, init_func) in enumerate(init_funcs):\n",
    "            init_func(tensor[i * fan_in : (i + 1) * fan_in, :])\n",
    "        \n",
    "    def _inner_uniform(tensor):\n",
    "        fan_in = nn.init._calculate_correct_fan(tensor, 'fan_in')\n",
    "        nn.init.uniform_(tensor, -math.sqrt(3 / fan_in), math.sqrt(3 / fan_in))\n",
    "    \n",
    "    for i in range(rnn.num_layers):\n",
    "        _concat_init(\n",
    "            getattr(rnn, 'weight_ih_l{}'.format(i)),\n",
    "            [_inner_uniform, _inner_uniform, _inner_uniform]\n",
    "        )\n",
    "        torch.nn.init.constant_(getattr(rnn, 'bias_ih_l{}'.format(i)), 0)\n",
    "\n",
    "        _concat_init(\n",
    "            getattr(rnn, 'weight_hh_l{}'.format(i)),\n",
    "            [_inner_uniform, _inner_uniform, nn.init.orthogonal_]\n",
    "        )\n",
    "        torch.nn.init.constant_(getattr(rnn, 'bias_hh_l{}'.format(i)), 0)\n",
    "    \n",
    "def init_ln(module):\n",
    "    if isinstance(module, nn.Embedding):\n",
    "        module.weight.data.normal_(mean=0.0, std=1.0)\n",
    "        if module.padding_idx is not None:\n",
    "            module.weight.data[module.padding_idx].zero_()\n",
    "    elif isinstance(module, nn.LayerNorm):\n",
    "        module.bias.data.zero_()\n",
    "        module.weight.data.fill_(1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7edf7b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, momentum):\n",
    "        \n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, \n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=(3, 3), stride=(1, 1),\n",
    "                              padding=(1, 1), bias=False)\n",
    "                              \n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels, \n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=(3, 3), stride=(1, 1),\n",
    "                              padding=(1, 1), bias=False)\n",
    "                              \n",
    "        self.bn1 = nn.BatchNorm2d(out_channels, momentum)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels, momentum)\n",
    "\n",
    "        self.init_weight()\n",
    "        \n",
    "    def init_weight(self):\n",
    "        init_layer(self.conv1)\n",
    "        init_layer(self.conv2)\n",
    "        init_bn(self.bn1)\n",
    "        init_bn(self.bn2)\n",
    "\n",
    "        \n",
    "    def forward(self, input, pool_size=(2, 2), pool_type='avg'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          input: (batch_size, in_channels, time_steps, freq_bins)\n",
    "        Outputs:\n",
    "          output: (batch_size, out_channels, classes_num)\n",
    "        \"\"\"\n",
    "\n",
    "        x = F.relu_(self.bn1(self.conv1(input)))\n",
    "        #print(x)\n",
    "        x = F.relu_(self.bn2(self.conv2(x)))\n",
    "        \n",
    "        if pool_type == 'avg':\n",
    "            x = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2ca7ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model=768, nhead=8):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        \n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead,batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=4)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        output = self.transformer_encoder(inputs)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f492abd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# アコースティックモデル\n",
    "class AcousticModelCRnn8Dropout(nn.Module):\n",
    "    def __init__(self, classes_num, midfeat, momentum):\n",
    "        super(AcousticModelCRnn8Dropout, self).__init__()\n",
    "\n",
    "        self.conv_block1 = ConvBlock(in_channels=1, out_channels=48, momentum=momentum)\n",
    "        self.conv_block2 = ConvBlock(in_channels=48, out_channels=64, momentum=momentum)\n",
    "        self.conv_block3 = ConvBlock(in_channels=64, out_channels=96, momentum=momentum)\n",
    "        self.conv_block4 = ConvBlock(in_channels=96, out_channels=128, momentum=momentum)\n",
    "\n",
    "        self.fc5 = nn.Linear(midfeat, 768, bias=False)\n",
    "        self.bn5 = nn.BatchNorm1d(768, momentum=momentum)\n",
    "        \n",
    "        self.ln1 = nn.LayerNorm(768)\n",
    "        self.pe = PositionalEncoding(d_model=768, dropout=0.1)\n",
    "\n",
    "        self.fc = nn.Linear(768, classes_num, bias=True)\n",
    "        \n",
    "        self.encoder_layer = TransformerEncoder()\n",
    "        \n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_layer(self.fc5)\n",
    "        init_bn(self.bn5)\n",
    "        init_layer(self.fc)\n",
    "        init_ln(self.ln1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          input: (batch_size, channels_num, time_steps, freq_bins)\n",
    "        Outputs:\n",
    "          output: (batch_size, time_steps, classes_num)\n",
    "        \"\"\"\n",
    "\n",
    "        x = self.conv_block1(input, pool_size=(1, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block2(x, pool_size=(1, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block3(x, pool_size=(1, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block4(x, pool_size=(1, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training) # [batch_size, 128, 1001, 14]\n",
    "        \n",
    "        x = x.transpose(1, 2).flatten(2)  # [batch_size, 1001, 1792]\n",
    "\n",
    "        x = F.relu(self.fc5(x)) # [batch_size, 1001, 768]\n",
    "        x = self.ln1(x)\n",
    "        x = F.dropout(x, p=0.2, training=self.training, inplace=True)  # [batch_size, 1001, 768]\n",
    "        x = self.pe(x) # [batch_soze, 1001, 768]\n",
    "        \n",
    "        x = self.encoder_layer(x)  # [batch_size, 1001, 768]\n",
    "        x = F.dropout(x, p=0.5, training=self.training, inplace=False)\n",
    "        \n",
    "        output = torch.sigmoid(self.fc(x))\n",
    "        \n",
    "        # この下にTransformerのEncoder部分(4層)を書く(to do)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b30b7964",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_batch = torch.ones(10, 1, 1001, 229)\n",
    "NET = AcousticModelCRnn8Dropout(momentum=0.01, midfeat=1792, classes_num = 88)\n",
    "outputs = NET(inputs_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8ed9075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1001, 88])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d1be6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
